_save_hyperparams: true
activations:
- !!python/object:torch.nn.modules.activation.GELU
  _backward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _backward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _buffers: {}
  _forward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_always_called: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _is_full_backward_hook: null
  _load_state_dict_post_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _load_state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _modules: {}
  _non_persistent_buffers_set: !!set {}
  _parameters: {}
  _state_dict_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  approximate: none
  training: true
add_hidden_layer_batchnorm: true
add_input_layer_batchnorm: false
hidden:
- 128
- 64
input_size: 11
loss: !!python/object:ml_mr.utils.quantiles.QuantileLossMulti
  quantiles: !!python/object/apply:torch._utils._rebuild_tensor_v2
  - !!python/object/apply:torch.storage._load_from_bytes
    - !!binary |
      gAKKCmz8nEb5IGqoUBkugAJN6QMugAJ9cQAoWBAAAABwcm90b2NvbF92ZXJzaW9ucQFN6QNYDQAA
      AGxpdHRsZV9lbmRpYW5xAohYCgAAAHR5cGVfc2l6ZXNxA31xBChYBQAAAHNob3J0cQVLAlgDAAAA
      aW50cQZLBFgEAAAAbG9uZ3EHSwR1dS6AAihYBwAAAHN0b3JhZ2VxAGN0b3JjaApGbG9hdFN0b3Jh
      Z2UKcQFYCQAAADIxOTI2NDI1NnECWAMAAABjcHVxA0sFTnRxBFEugAJdcQBYCQAAADIxOTI2NDI1
      NnEBYS4FAAAAAAAAAM3MzD2amZk+AAAAPzMzMz9mZmY/
  - 0
  - !!python/tuple
    - 5
  - !!python/tuple
    - 1
  - false
  - !!python/object/apply:collections.OrderedDict
    - []
lr: 0.0001
n_quantiles: 5
out: 5
weight_decay: 0
